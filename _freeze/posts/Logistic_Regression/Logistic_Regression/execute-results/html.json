{
  "hash": "761ffa5b3b89524f787f0e2f742112a0",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Logistic regression\"\nauthor: Jinii\ndate: '2024-09-010'\ncategories: [bigdata]\njupyter: python3\n---\n\n\n종속변수: 백혈병 세포 관측 불가 여부 (REMISS), 1이면 관측 안됨을 의미\n\n독립변수:\n골수의 세포성 (CELL)\n골수편의 백혈구 비율 (SMEAR)\n골수의 백혈병 세포 침투 비율 (INFIL)\n골수 백혈병 세포의 라벨링 인덱스 (LI)\n말초혈액의 백혈병 세포 수 (BLAST)\n치료 시작 전 최고 체온 (TEMP)\n\n## 문제 1.\n\n데이터를 로드하고, 로지스틱 회귀모델을 적합하고, 회귀 표를 작성하세요.\n\n::: {#8663f378 .cell execution_count=1}\n``` {.python .cell-code}\n# 데이터 로드\nimport pandas as pd\n\ndf = pd.read_csv('../../data/leukemia_remission.txt', delim_whitespace= True) # delim_whitespace : 공백 지우기\nprint(df.head())\n\ntrain = df.drop(columns=('REMISS')) # 독립변수만\n\n# 로지스틱 회귀모델 적합, 회귀 표 작성\nimport statsmodels.api as sm\nmodel = sm.formula.logit(\"REMISS ~ CELL + SMEAR + INFIL + LI + BLAST + TEMP\", data=df).fit()\nprint(model.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   REMISS  CELL  SMEAR  INFIL   LI  BLAST  TEMP\n0       1   0.8   0.83   0.66  1.9   1.10  1.00\n1       1   0.9   0.36   0.32  1.4   0.74  0.99\n2       0   0.8   0.88   0.70  0.8   0.18  0.98\n3       0   1.0   0.87   0.87  0.7   1.05  0.99\n4       1   0.9   0.75   0.68  1.3   0.52  0.98\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2104\\3209557587.py:4: FutureWarning:\n\nThe 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.399886\n         Iterations 10\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                 REMISS   No. Observations:                   27\nModel:                          Logit   Df Residuals:                       20\nMethod:                           MLE   Df Model:                            6\nDate:                Tue, 10 Sep 2024   Pseudo R-squ.:                  0.3718\nTime:                        10:29:30   Log-Likelihood:                -10.797\nconverged:                       True   LL-Null:                       -17.186\nCovariance Type:            nonrobust   LLR p-value:                   0.04670\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     64.2581     74.965      0.857      0.391     -82.670     211.187\nCELL          30.8301     52.135      0.591      0.554     -71.353     133.013\nSMEAR         24.6863     61.526      0.401      0.688     -95.903     145.275\nINFIL        -24.9745     65.281     -0.383      0.702    -152.923     102.974\nLI             4.3605      2.658      1.641      0.101      -0.849       9.570\nBLAST         -0.0115      2.266     -0.005      0.996      -4.453       4.430\nTEMP        -100.1734     77.753     -1.288      0.198    -252.567      52.220\n==============================================================================\n\nPossibly complete quasi-separation: A fraction 0.11 of observations can be\nperfectly predicted. This might indicate that there is complete\nquasi-separation. In this case some parameters will not be identified.\n```\n:::\n:::\n\n\n## 문제 2.\n\n해당 모델은 통계적으로 유의한가요? 그 이유를 검정통계량를 사용해서 설명하시오.\n\n::: {#c781bf6e .cell execution_count=2}\n``` {.python .cell-code}\n# −2(ℓ(𝛽)̂ (0) − ℓ(𝛽)̂ )  =  -2*(-17.186+10.797)  = 12.779\nfrom scipy.stats import chi2\n1 - chi2.cdf(12.779, df=6)  # 0.0466828104726148\n\n# LLR p-value: 0.0467 < 유의수준 0.05보다 작으니까 통계적으로 유의하다고 할 수 있다.\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\nnp.float64(0.0466828104726148)\n```\n:::\n:::\n\n\n## 문제 3.\n\n유의수준이 0.2를 기준으로 통계적으로 유의한 변수는 몇개이며, 어느 변수 인가요?\n\n::: {#555c3e6b .cell execution_count=3}\n``` {.python .cell-code}\n# P>|z|가 0.2보다 작은 LI, TEMP가 유의하다\n```\n:::\n\n\n## 문제 4\n\n다음 환자에 대한 오즈는 얼마인가요?\n\nCELL (골수의 세포성): 65%\nSMEAR (골수편의 백혈구 비율): 45%\nINFIL (골수의 백혈병 세포 침투 비율): 55%\nLI (골수 백혈병 세포의 라벨링 인덱스): 1.2\nBLAST (말초혈액의 백혈병 세포 수): 1.1세포/μL\nTEMP (치료 시작 전 최고 체온): 0.9\n\n::: {#ad0b3d6a .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nlog_odds=64.2581 + 30.8301*0.65 + 24.6863*0.45 + -24.9745*0.55 + 4.3605*1.2 + -0.0115*1.1 + -100.1734*0.9\nodds = np.exp(log_odds) # 0.03817459641135519\nprint(odds)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.03817459641135519\n```\n:::\n:::\n\n\n## 문제 5\n\n위 환자의 혈액에서 백혈병 세포가 관측되지 않은 확률은 얼마인가요?\n\n::: {#e0dca07a .cell execution_count=5}\n``` {.python .cell-code}\np_hat = odds / (odds + 1) # 0.03677088280074742\nprint(p_hat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.03677088280074742\n```\n:::\n:::\n\n\n## 문제 6\n\nTEMP 변수의 계수는 얼마이며, 해당 계수를 사용해서 TEMP 변수가 백혈병 치료에 대한 영향을 설명하시오.\n\n::: {#dc8ae5d4 .cell execution_count=6}\n``` {.python .cell-code}\nnp.exp(-100.1734)\n# 3.13e-44 - > 0에 가까운 값입니다.\n# 체온이 1단위 상승할 때 백혈병 세포가 관측되지 않을 확률이 (오즈비만큼 변동)거의 없어지는 것을 의미\n# -> 온도가 높아질수록 백혈병 세포가 관측될 확률 높아짐.\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nnp.float64(3.1278444454718357e-44)\n```\n:::\n:::\n\n\n## 문제 7\n\nCELL 변수의 99% 오즈비에 대한 신뢰구간을 구하시오.\n\n::: {#6340ec91 .cell execution_count=7}\n``` {.python .cell-code}\n# CELL 변수의 베타에 대한 99 : (베타_hat - z(0.005)*SE(std_err) , 베타_hat + z(0.005)*SE)\nfrom scipy.stats import norm\nz0005 = norm.ppf(0.995, loc=0, scale=1)\n30.8301 - 52.135*z0005 , 30.8301 + 52.135*z0005\nnp.exp(30.8301 - 52.135*z0005) , np.exp(30.8301 + 52.135*z0005)  # (1.1683218982002717e-45, 5.141881884993857e+71)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n(np.float64(1.1683218982002717e-45), np.float64(5.141881884993857e+71))\n```\n:::\n:::\n\n\n## 문제 8\n\n주어진 데이터에 대하여 로지스틱 회귀 모델의 예측 확률을 구한 후 50% 이상인 경우 1로 처리하여, 혼동 행렬를 구하시오.\n\n::: {#c7c73f36 .cell execution_count=8}\n``` {.python .cell-code}\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\ny_pred = model.predict(train)\nresult = pd.DataFrame({'y_pred' : y_pred})\nresult['result'] = np.where(result['y_pred']>=0.5, 1,0)\n\nconf_mat = confusion_matrix(y_true = df['REMISS'], y_pred = result['result'], labels=[1,0])\np = ConfusionMatrixDisplay(confusion_matrix = conf_mat, display_labels = ('관측불가_1', '관측가능_0'))\nplt.rcParams['font.family'] = 'Malgun Gothic'\np.plot(cmap=\"Blues\")\n```\n\n::: {.cell-output .cell-output-display}\n![](Logistic_Regression_files/figure-html/cell-9-output-1.png){width=551 height=430}\n:::\n:::\n\n\n## 문제 9\n\n해당 모델의 Accuracy는 얼마인가요?\n\n::: {#47cd0c73 .cell execution_count=9}\n``` {.python .cell-code}\n(5+15)/(5+3+4+15)  # 0.7407407407407407\n\nfrom sklearn.metrics import accuracy_score, f1_score\naccuracy_score(df['REMISS'], result['result'])  # 0.7407407407407407\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0.7407407407407407\n```\n:::\n:::\n\n\n## 문제 10\n\n해당 모델의 F1 Score를 구하세요.\n\n::: {#cd4bb1c0 .cell execution_count=10}\n``` {.python .cell-code}\nprecision = 5/(5+3)\nrecall = 5/(5+4)\n\n2 / (1/precision + 1/recall)   # 0.5882352941176471\n\nf1_score(df['REMISS'], result['result'])  # 0.5882352941176471\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\nnp.float64(0.5882352941176471)\n```\n:::\n:::\n\n\n",
    "supporting": [
      "Logistic_Regression_files"
    ],
    "filters": [],
    "includes": {}
  }
}